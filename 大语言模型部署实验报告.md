# 大语言模型部署实验报告

## 1 大语言模型简介

大语言模型（Large Language Model, LLM）是一种基于深度学习的人工智能模型，特别擅长处理和生成自然语言文本。大语言模型通常基于Transformer架构，其核心是自注意力机制（self-attention），可以高效地捕捉句子中的长距离依赖关系。以下是大语言模型的一些特点：

1. **训练数据**：  
   大语言模型在大量文本数据上进行训练，包括互联网、书籍、文章等多种来源。通过训练，模型学习语言的结构、词汇意义及句子间的关系。

2. **模型规模**：  
   参数数量从数亿到数千亿不等，参数越多，模型表现通常越好，但也需要更多计算资源。

3. **应用领域**：  
   - 文本生成（写作辅助、新闻生成）  
   - 语言翻译  
   - 问答系统（搜索引擎、客服）  
   - 对话机器人  
   - 文本分析（情感分析、主题分类）  

4. **优缺点**：  
   - **优点**：高质量文本生成，多语言任务处理能力强。  
   - **缺点**：计算资源需求高；可能生成不准确内容或存在数据偏见。

---

## 2 在魔搭社区上部署大语言模型

### 2.1 环境准备
1. 注册魔搭社区账号并绑定阿里云账号以获取免费CPU资源。  
2. 通过命令行下载以下模型：  
   - 通义千问Qwen-7B-Chat  
   - 智谱ChatGLM3-6B  
   - 百川2-7B-对话模型  

**部署命令**：  
```bash
git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git
git clone https://www.modelscope.cn/qwen/Qwen-7B-Chat.git
git clone https://www.modelscope.cn/baichuan-inc/Baichuan2-7B-Chat.git
```

**成功部署截图**：
![模型下载成功截图1](git_result_cpu.png) 
![模型下载成功截图2](git_result_cpu_2.png) 
![模型下载成功截图2](git_result_cpu_3.png)  
*图1：模型下载完成提示*

---

## 3 模型测试与问答结果

### 3.1 测试问题设计
针对以下问题测试模型表现：  
1. 季节穿衣对比（冬天 vs 夏天）  
2. 单身狗原因的双关语  
3. 多层嵌套的“谁不知道”  
4. 明明与白白的喜欢关系  
5. “意思”的多重含义  

### 3.2 测试结果

#### **ChatGLM3-6B 测试**
**代码示例**：  
```python
from transformers import TextStreamer, AutoTokenizer, AutoModelForCausalLM
model_name = "/mnt/data/chatglm2-6b"
prompt = "请说出以下两句话区别在哪里？ 1、冬天：能穿多少穿多少2、夏天：能穿多少穿多少"
tokenizer = AutoTokenizer.from_pretrained(
model_name,
trust_remote_code=True
)
model = AutoModelForCausalLM.from_pretrained(
model_name,
trust_remote_code=True,
torch_dtype="auto" # 自动选择float32/float16（根据模型配置）
).eval()
inputs = tokenizer(prompt, return_tensors="pt").input_ids
streamer = TextStreamer(tokenizer)
outputs = model.generate(inputs, streamer=streamer, max_new_tokens=300)
```

**回答截图**：  
![ChatGLM3回答截图1](chatglm3_7B_cpu_summer_and_winter.png)  

![ChatGLM3回答截图2](chatglm3_7B_cpu_solo.png)  

![ChatGLM3回答截图3](chatglm3_7B_cpu_not_know.png)  

![ChatGLM3回答截图4](chatglm3_7B_cpu_like.png)  

![ChatGLM3回答截图5](chatglm3_7B_cpu_meaning.png)  
*图2：ChatGLM3对对五个问题的综合回答*


#### **Qwen-7B-Chat 测试**
**回答截图**：  
![Qwen回答汇总](qwen_7B_cpu_summer_and_winter.png)  

![Qwen回答汇总](qwen_7B_cpu_solo.png)  

![Qwen回答汇总](qwen_7B_cpu_not_know.png)  

![Qwen回答汇总](qwen_7B_cpu_like.png)  

![Qwen回答汇总](qwen_7B_cpu_meaning.png)  
*图3：Qwen对五个问题的综合回答*

---

- ### 4 横向对比分析（根据实际测试结果修订）

  #### 4.1 关键问题测试结果对比

  **1. 季节穿衣对比问题**  
  - **ChatGLM3-6B**  
    ![ChatGLM3季节回答](chatglm3_7B_cpu_summer_and_winter.png)  
    *仅指出季节不同，未深入分析语境差异。*  

  - **Qwen-7B-Chat**  
    ![Qwen季节回答](qwen_7B_cpu_summer_and_winter.png)  
    *详细分析语气差异（冬季严肃保暖 vs 夏季轻松防晒），逻辑更清晰。*  

  **结论**：Qwen对语境理解更全面，ChatGLM3回答较简略。

  ---

  **2. 单身狗原因双关语**  
  - **ChatGLM3-6B**  
    ![ChatGLM3单身狗回答](chatglm3_7B_cpu_solo.png)  
    *回答不完整，仅显示部分内容且逻辑混乱。*  

  - **Qwen-7B-Chat**  
    ![Qwen单身狗回答](qwen_7B_cpu_solo.png)  
    *明确区分两句话的概括性与具体性，分析更结构化。*  

  **结论**：Qwen能准确捕捉双关语内涵，ChatGLM3表现较差。

  ---

  **3. “谁不知道”嵌套问题**  
  - **ChatGLM3-6B**  
    ![ChatGLM3嵌套回答](chatglm3_7B_cpu_not_know.png)  
    *判定为“无法解决的问题”，未给出明确结论。*  

  - **Qwen-7B-Chat**  
    ![Qwen嵌套回答](qwen_7B_cpu_not_know.png)  
    *分步拆解逻辑关系，最终指出“说话者自己不知道”。*  

  **结论**：Qwen逻辑分析能力更强，ChatGLM3回避问题。

  ---

  **4. 明明与白白关系**  
  - **ChatGLM3-6B**  
    ![ChatGLM3关系回答](chatglm3_7B_cpu_like.png)  
    
  - **Qwen-7B-Chat**  
    ![Qwen关系回答](qwen_7B_cpu_like.png)  

  **结论**：在这个问答中，两者不相上下，都是错的

  ---

  **5. “意思”多重含义**  
  - **ChatGLM3-6B**  
    ![ChatGLM3意思回答](chatglm3_7B_cpu_meaning.png)  
    *逐条解释但格式混乱，部分内容缺失。*  

  - **Qwen-7B-Chat**  
    ![Qwen意思回答](qwen_7B_cpu_meaning.png)  
    *虽未完整显示，但结构清晰，尝试分析不同语境含义。*  

  **结论**：Qwen解释更系统，ChatGLM3输出稳定性不足。

  ---

  #### 4.2 综合对比与建议

  | **能力维度**     | **ChatGLM3-6B**              | **Qwen-7B-Chat**           |
  | ---------------- | ---------------------------- | -------------------------- |
  | **复杂逻辑分析** | 较弱（回避嵌套问题）         | 强（分步拆解逻辑）         |
  | **语境理解**     | 一般（忽略语气差异）         | 优秀（结合季节特点分析）   |
  | **回答稳定性**   | 低（部分生成内容错误或缺失） | 高（结构清晰，输出完整）   |
  | **双关语处理**   | 差（回答不完整）             | 良好（区分字面与隐含意义） |

  **最终建议**：  
  - **优先选择Qwen-7B-Chat**：在逻辑分析、语境理解和回答稳定性上均表现更优，适合需要精准答案的场景。  
  - **ChatGLM3-6B适用场景**：资源有限环境下的简单问答，但需人工校验输出结果。  


---

## 5 项目公开链接
- GitHub仓库：[点击访问](https://github.com/zzy0304Raymond/Comparing-Language-Models-Chinese-Semantic-Understanding)  

---

**注**：所有截图均为实验过程中实际生成，完整截图集见附件。